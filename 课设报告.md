# 医疗知识图谱问答系统 (KGQA) 课程设计报告

---

## 二、问题背景和相关工作介绍

### 2.1 知识图谱问答概述

知识图谱问答（Knowledge Graph Question Answering, KGQA）是自然语言处理领域的重要研究方向，旨在利用结构化的知识图谱回答用户的自然语言问题。与传统的信息检索方法不同，KGQA能够理解问题的语义结构，并通过图谱中的实体和关系进行精确推理，返回结构化的答案。

KGQA系统的核心挑战包括：
- **自然语言理解**：将用户问题转换为结构化查询
- **实体识别与链接**：识别问题中的实体并映射到知识图谱
- **关系推理**：确定实体间的关系路径
- **答案生成**：从图谱中检索并组织答案

### 2.2 医疗领域知识图谱的重要性

医疗健康领域是知识图谱应用的重要场景。医疗知识具有以下特点：
- **专业性强**：涉及大量专业术语和复杂的医学概念
- **关系复杂**：疾病、症状、药物、检查等实体之间存在多种关联
- **知识密集**：需要整合多源异构数据
- **准确性要求高**：医疗决策对准确性有严格要求

医疗知识图谱问答系统能够帮助：
- 患者快速获取疾病相关信息
- 医生辅助诊断和用药参考
- 医学教育和知识普及

### 2.3 相关工作

#### 2.3.1 知识图谱构建

知识图谱构建主要包括三个阶段：
1. **知识抽取**：从结构化数据（数据库、表格）和非结构化数据（文本）中提取实体和关系
2. **知识融合**：整合多源数据，消解实体歧义，处理冲突信息
3. **知识存储**：使用图数据库（如Neo4j、JanusGraph）存储和管理知识

代表性工作包括：
- **CMeKG**：中文医学知识图谱，包含疾病、症状、药物等实体
- **CM3KG**：中文医学常识知识图谱，提供更丰富的医学常识信息
- **OMKG**：开放医学知识图谱，整合多源医学数据

#### 2.3.2 命名实体识别（NER）

命名实体识别是从文本中识别特定类型实体的任务。在医疗领域，需要识别：
- 疾病名称（Disease）
- 症状描述（Symptom）
- 药物名称（Drug）
- 检查项目（Exam）
- 身体部位（Body）

主流方法演进：
- **基于规则**：依赖词典和正则表达式，准确率高但召回率有限
- **传统机器学习**：CRF、HMM等序列标注模型
- **深度学习**：BiLSTM-CRF、BERT-CRF等预训练模型方法

#### 2.3.3 实体链接

实体链接将识别出的实体提及（mention）映射到知识图谱中的规范实体。主要挑战：
- **同义词处理**：如"感冒"与"上呼吸道感染"
- **歧义消解**：如"苹果"可指水果或公司
- **别名识别**：如"阿司匹林"与"乙酰水杨酸"

常用方法：
- **字符串匹配**：精确匹配和模糊匹配（编辑距离、Jaccard相似度）
- **向量表示**：使用词嵌入计算语义相似度
- **图嵌入**：利用知识图谱结构信息

#### 2.3.4 关系抽取

关系抽取旨在识别文本中实体对之间的语义关系。方法包括：
- **基于模式**：预定义关系模板
- **监督学习**：使用标注数据训练分类器
- **远程监督**：利用已有知识图谱自动生成训练数据
- **预训练模型**：基于BERT等模型的关系分类

#### 2.3.5 知识图谱问答

KGQA方法主要分为两类：

1. **语义解析方法**（Semantic Parsing）
   - 将自然语言问题转换为结构化查询（如SPARQL、Cypher）
   - 优点：可解释性强，答案准确
   - 缺点：需要设计复杂的语法规则

2. **信息检索方法**（Information Retrieval）
   - 将问题和候选答案编码为向量，计算相似度
   - 优点：灵活性高，易于扩展
   - 缺点：难以处理复杂推理

### 2.4 现有方法的局限性

1. **数据源单一**：大多数系统仅使用单一数据源，知识覆盖有限
2. **融合能力弱**：缺乏有效的多源知识融合机制
3. **扩展性差**：难以适应新的实体类型和关系
4. **评估不完善**：缺乏针对性的评估指标和基准数据集

---

## 三、解决思路

### 3.1 系统整体架构

本系统采用分层架构设计，自底向上分为四层：

```
┌─────────────────────────────────────────────────────────────┐
│                      服务层 (Service Layer)                   │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │
│  │  REST API   │  │  意图识别   │  │  Cypher查询生成     │  │
│  └─────────────┘  └─────────────┘  └─────────────────────┘  │
├─────────────────────────────────────────────────────────────┤
│                      存储层 (Storage Layer)                   │
│  ┌─────────────────────────────────────────────────────────┐│
│  │                    Neo4j 图数据库                        ││
│  │  节点: Disease, Symptom, Drug, Exam, Food, Department   ││
│  │  关系: HAS_SYMPTOM, RECOMMEND_DRUG, TREATED_IN, ...     ││
│  └─────────────────────────────────────────────────────────┘│
├─────────────────────────────────────────────────────────────┤
│                      融合层 (Fusion Layer)                    │
│  ┌───────────┐  ┌───────────┐  ┌───────────┐  ┌───────────┐│
│  │ 文本规范化 │  │ 实体链接  │  │ 冲突检测  │  │ 边评分    ││
│  └───────────┘  └───────────┘  └───────────┘  └───────────┘│
├─────────────────────────────────────────────────────────────┤
│                      数据层 (Data Layer)                      │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │
│  │  CM3KG      │  │  CMeKG      │  │  其他数据源         │  │
│  │Disease.csv  │  │  triples    │  │  (可扩展)           │  │
│  │medical.csv  │  │             │  │                     │  │
│  └─────────────┘  └─────────────┘  └─────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 数据处理流程

#### 3.2.1 数据转换模块

CM3KG数据集包含两个核心文件：

**Disease.csv** 格式：
```
实体名[实体类型], 谓词, 值
例如: 感冒[疾病], 症状, 发热
```

**medical.csv** 格式：
```csv
name,symptom,check,recommand_drug,...
感冒,"['发热','咳嗽']","['血常规']",...
```

转换流程：
1. **编码检测**：自动识别文件编码（UTF-8/GBK/GB18030）
2. **实体解析**：从"实体名[类型]"格式提取实体名称和类型
3. **谓词映射**：将中文谓词转换为标准关系类型
4. **属性处理**：长文本字段（描述、病因等）作为节点属性存储
5. **三元组生成**：输出标准JSONL格式

#### 3.2.2 类型映射

实体类型映射：
| 中文类型 | 英文标签 |
|---------|---------|
| 疾病 | Disease |
| 症状 | Symptom |
| 药物/药品 | Drug |
| 检查 | Exam |
| 食物 | Food |
| 科室 | Department |

关系类型映射：
| 中文谓词 | 关系类型 | 说明 |
|---------|---------|------|
| 症状 | HAS_SYMPTOM | 疾病→症状 |
| 并发症 | HAS_COMPLICATION | 疾病→疾病 |
| 推荐药品 | RECOMMEND_DRUG | 疾病→药物 |
| 常用药品 | COMMON_DRUG | 疾病→药物 |
| 宜吃食物 | DO_EAT | 疾病→食物 |
| 忌吃食物 | NOT_EAT | 疾病→食物 |
| 就诊科室 | TREATED_IN | 疾病→科室 |

#### 3.2.3 反向关系处理

对于"症状→可能疾病→疾病"这种反向关系，需要交换头尾实体：
```
原始: 发热[症状] → 可能疾病 → 感冒
转换: 感冒[Disease] → HAS_SYMPTOM → 发热[Symptom]
```

### 3.3 知识融合策略

#### 3.3.1 实体链接

采用Union-Find（并查集）算法进行实体归一化：

1. **初始化**：每个实体自成一个集合
2. **规则合并**：基于预定义规则合并同义实体
   - 括号变体："肺炎（细菌性）" = "细菌性肺炎"
   - 前缀/后缀："急性支气管炎" ⊃ "支气管炎"
3. **模糊匹配**（可选）：基于编辑距离合并相似实体
4. **规范名称**：选择最长名称作为规范形式

#### 3.3.2 冲突检测

检测同一关系下的冲突值：
- **单值关系**：如"患病比例"只能有一个值
- **多值关系**：如"HAS_SYMPTOM"允许多个值

冲突处理策略：
- 保留置信度最高的值
- 标记冲突边供人工审核

#### 3.3.3 边评分

综合多因素计算边的可信度分数：

$$EdgeScore = w_f \cdot FreqScore + w_s \cdot SourceScore + w_c \cdot ConfScore$$

其中：
- $FreqScore = \min(frequency / 10, 1.0)$：归一化频次分数
- $SourceScore = \sum weight(source) / count$：来源权重平均
- $ConfScore$：原始置信度平均值
- $w_f, w_s, w_c$：权重系数（默认各0.3, 0.3, 0.4）

### 3.4 图数据库存储

#### 3.4.1 数据模型

节点结构：
```
(:Disease {
    name: "感冒",
    aliases: ["上呼吸道感染", "普通感冒"],
    desc: "上呼吸道感染的简称...",
    cause: "病毒感染...",
    prevent: "注意保暖...",
    created_at: "2024-01-01T00:00:00"
})
```

关系结构：
```
(:Disease)-[:HAS_SYMPTOM {
    source: "CM3KG",
    confidence: 1.0,
    frequency: 5,
    edge_score: 0.85
}]->(:Symptom)
```

#### 3.4.2 批量导入

使用UNWIND进行高效批量导入：
```cypher
UNWIND $batch AS row
MERGE (h:Disease {name: row.head})
MERGE (t:Symptom {name: row.tail})
MERGE (h)-[r:HAS_SYMPTOM]->(t)
SET r.source = row.source, r.confidence = row.confidence
```

### 3.5 问答服务流程

```
用户问题 → NER实体识别 → 意图分类 → Cypher生成 → 图谱查询 → 结果返回
    │           │            │           │           │          │
    │           ▼            ▼           ▼           ▼          │
    │     "肺炎的症状"   disease_     MATCH...    [咳嗽,      ◄──┘
    │     → [肺炎]      to_symptom   RETURN...    发热,...]
    │
    └──────────────────────────────────────────────────────────►
```

#### 3.5.1 意图识别

基于规则的意图分类：

| 意图 | 触发词示例 |
|-----|-----------|
| disease_to_symptom | "症状是什么"、"有什么表现" |
| symptom_to_disease | "什么病"、"可能是什么病" |
| disease_to_drug | "吃什么药"、"用什么药" |
| disease_to_department | "挂什么科"、"去哪个科室" |

#### 3.5.2 Cypher查询生成

根据意图生成对应的Cypher查询模板：

```python
# disease_to_symptom
MATCH (d:Disease {name: $entity})-[:HAS_SYMPTOM]->(s:Symptom)
RETURN s.name AS result

# symptom_to_disease
MATCH (d:Disease)-[:HAS_SYMPTOM]->(s:Symptom {name: $entity})
RETURN d.name AS result
```

### 3.6 评估体系

评估指标：
- **可执行率**：查询能够正常执行的比例
- **Accuracy@1**：首个结果正确的比例
- **Precision**：返回结果中正确答案的比例
- **Recall**：正确答案被返回的比例
- **F1 Score**：Precision和Recall的调和平均
- **Coverage**：有结果返回的问题比例
- **Latency**：查询响应时间

---

## 四、算法伪代码

### 4.1 实体链接算法（Union-Find）

```
Algorithm: EntityLinking
Input: entity_list - 实体列表
Output: canonical_map - 实体到规范名称的映射

1. class UnionFind:
2.     parent = {}  // 父节点映射
3.     rank = {}    // 秩（用于优化合并）
4.
5.     function FIND(x):
6.         if x not in parent:
7.             parent[x] = x
8.             rank[x] = 0
9.         if parent[x] ≠ x:
10.            parent[x] = FIND(parent[x])  // 路径压缩
11.        return parent[x]
12.
13.    function UNION(x, y):
14.        root_x = FIND(x)
15.        root_y = FIND(y)
16.        if root_x = root_y:
17.            return
18.        // 按秩合并
19.        if rank[root_x] < rank[root_y]:
20.            parent[root_x] = root_y
21.        else if rank[root_x] > rank[root_y]:
22.            parent[root_y] = root_x
23.        else:
24.            parent[root_y] = root_x
25.            rank[root_x] = rank[root_x] + 1

26. function MERGE_BY_RULES(entities):
27.    for each entity in entities:
28.        // 规则1: 括号变体
29.        if entity contains "（" or "）":
30.            normalized = remove_parentheses(entity)
31.            if normalized in entities:
32.                UNION(entity, normalized)
33.
34.        // 规则2: 前缀匹配
35.        for each other in entities:
36.            if other ≠ entity and entity.endswith(other):
37.                UNION(entity, other)

38. function BUILD_CANONICAL_MAP(entities):
39.    groups = {}  // 根节点到成员列表的映射
40.    for each entity in entities:
41.        root = FIND(entity)
42.        if root not in groups:
43.            groups[root] = []
44.        groups[root].append(entity)
45.
46.    canonical_map = {}
47.    for each (root, members) in groups:
48.        // 选择最长名称作为规范名称
49.        canonical = max(members, key=length)
50.        for each member in members:
51.            canonical_map[member] = canonical
52.
53.    return canonical_map
```

### 4.2 边评分算法

```
Algorithm: EdgeScoring
Input: raw_triples - 原始三元组列表
       source_weights - 数据源权重配置
       w_f, w_s, w_c - 频次、来源、置信度权重
Output: scored_edges - 带分数的边列表

1. edge_info = {}  // (head, relation, tail) -> EdgeData

2. // 聚合同一边的多个来源
3. for each triple in raw_triples:
4.     key = (triple.head, triple.relation, triple.tail)
5.     if key not in edge_info:
6.         edge_info[key] = {
7.             sources: [],
8.             confidences: [],
9.             frequency: 0
10.        }
11.    edge_info[key].sources.append(triple.source)
12.    edge_info[key].confidences.append(triple.confidence)
13.    edge_info[key].frequency += 1

14. scored_edges = []

15. for each (key, data) in edge_info:
16.    // 计算频次分数
17.    freq_score = min(data.frequency / 10.0, 1.0)
18.
19.    // 计算来源分数
20.    source_total = 0
21.    for each src in data.sources:
22.        weight = source_weights.get(src, source_weights["default"])
23.        source_total += weight
24.    source_score = source_total / len(data.sources)
25.
26.    // 计算置信度分数
27.    conf_score = sum(data.confidences) / len(data.confidences)
28.
29.    // 综合评分
30.    edge_score = w_f * freq_score + w_s * source_score + w_c * conf_score
31.
32.    scored_edge = {
33.        head: key[0],
34.        relation: key[1],
35.        tail: key[2],
36.        frequency: data.frequency,
37.        source_score: source_score,
38.        confidence: conf_score,
39.        edge_score: edge_score,
40.        sources: unique(data.sources)
41.    }
42.    scored_edges.append(scored_edge)

43. return scored_edges
```

### 4.3 意图识别算法

```
Algorithm: IntentRecognition
Input: question - 用户问题
Output: (intent, entity) - 识别的意图和实体

1. // 定义意图模式
2. INTENT_PATTERNS = {
3.     "disease_to_symptom": [
4.         r"(.+?)的症状",
5.         r"(.+?)有什么表现",
6.         r"(.+?)有哪些症状",
7.         r"得了(.+?)会怎样"
8.     ],
9.     "symptom_to_disease": [
10.        r"(.+?)是什么病",
11.        r"(.+?)可能是什么病",
12.        r"哪些疾病会出现(.+?)的症状",
13.        r"(.+?)可能得了什么病"
14.    ],
15.    "disease_to_drug": [
16.        r"(.+?)吃什么药",
17.        r"(.+?)用什么药治疗",
18.        r"治疗(.+?)的药物"
19.    ],
20.    "disease_to_department": [
21.        r"(.+?)挂什么科",
22.        r"(.+?)去哪个科室",
23.        r"(.+?)应该看什么科"
24.    ]
25. }

26. function RECOGNIZE(question):
27.    question = normalize(question)  // 去除空格、标点规范化
28.
29.    for each (intent, patterns) in INTENT_PATTERNS:
30.        for each pattern in patterns:
31.            match = regex_match(pattern, question)
32.            if match:
33.                entity = match.group(1)
34.                entity = clean_entity(entity)  // 去除"的"等语气词
35.                return (intent, entity)
36.
37.    // 未匹配到模式，使用NER识别实体
38.    entities = NER_EXTRACT(question)
39.    if entities:
40.        // 根据关键词判断意图
41.        if contains_any(question, ["症状", "表现"]):
42.            return ("disease_to_symptom", entities[0])
43.        else if contains_any(question, ["什么病", "疾病"]):
44.            return ("symptom_to_disease", entities[0])
45.
46.    return (None, None)  // 无法识别
```

### 4.4 Cypher查询生成算法

```
Algorithm: CypherQueryGeneration
Input: intent - 意图类型
       entity - 查询实体
       top_k - 返回结果数量限制
Output: cypher_query - Cypher查询语句

1. // 查询模板定义
2. QUERY_TEMPLATES = {
3.     "disease_to_symptom": """
4.         MATCH (d:Disease)-[:HAS_SYMPTOM]->(s:Symptom)
5.         WHERE d.name = $entity OR $entity IN d.aliases
6.         RETURN s.name AS result
7.         LIMIT $top_k
8.     """,
9.
10.    "symptom_to_disease": """
11.        MATCH (d:Disease)-[:HAS_SYMPTOM]->(s:Symptom)
12.        WHERE s.name = $entity OR $entity IN s.aliases
13.        RETURN d.name AS result
14.        LIMIT $top_k
15.    """,
16.
17.    "disease_to_drug": """
18.        MATCH (d:Disease)-[:RECOMMEND_DRUG|COMMON_DRUG]->(dr:Drug)
19.        WHERE d.name = $entity OR $entity IN d.aliases
20.        RETURN dr.name AS result
21.        LIMIT $top_k
22.    """,
23.
24.    "disease_to_department": """
25.        MATCH (d:Disease)-[:TREATED_IN]->(dept:Department)
26.        WHERE d.name = $entity OR $entity IN d.aliases
27.        RETURN dept.name AS result
28.        LIMIT $top_k
29.    """
30. }

31. function GENERATE_QUERY(intent, entity, top_k):
32.    if intent not in QUERY_TEMPLATES:
33.        return None
34.
35.    template = QUERY_TEMPLATES[intent]
36.
37.    // 参数化查询，防止注入
38.    query = {
39.        cypher: template,
40.        parameters: {
41.            entity: entity,
42.            top_k: top_k
43.        }
44.    }
45.
46.    return query

47. function EXECUTE_QUERY(driver, query):
48.    with driver.session() as session:
49.        result = session.run(query.cypher, query.parameters)
50.        records = []
51.        for record in result:
52.            records.append(record["result"])
53.        return records
```

### 4.5 数据转换算法

```
Algorithm: CM3KGConversion
Input: disease_csv_path - Disease.csv路径
       medical_csv_path - medical.csv路径
Output: triples_jsonl - JSONL格式三元组文件

1. // 类型和关系映射
2. TYPE_MAPPING = {"疾病": "Disease", "症状": "Symptom", "药物": "Drug", ...}
3. RELATION_MAP = {"症状": "HAS_SYMPTOM", "并发症": "HAS_COMPLICATION", ...}
4. PROPERTY_MAP = {"简介": "desc", "病因": "cause", "预防方式": "prevent", ...}
5. REVERSE_RELATION_MAP = {"可能疾病": ("HAS_SYMPTOM", "Symptom", "Disease")}

6. seen_triples = Set()  // 去重集合
7. output_triples = []

8. function PARSE_ENTITY(raw_string):
9.     // 解析 "实体名[类型]" 格式
10.    match = regex("^(.+)\[(.+)\]$", raw_string)
11.    if match:
12.        name = match.group(1).strip()
13.        type_cn = match.group(2).strip()
14.        type_en = TYPE_MAPPING.get(type_cn, "Entity")
15.        return (name, type_en)
16.    return (raw_string.strip(), "Entity")

17. function PROCESS_DISEASE_CSV(path):
18.    encoding = detect_encoding(path)
19.
20.    for each row in read_csv(path, encoding):
21.        if len(row) < 3: continue
22.
23.        raw_entity, predicate, value = row[0], row[1], row[2]
24.        head, head_type = PARSE_ENTITY(raw_entity)
25.
26.        // 处理属性
27.        if predicate in PROPERTY_MAP:
28.            WRITE_PROPERTY(head, head_type, PROPERTY_MAP[predicate], value)
29.            continue
30.
31.        // 处理正向关系
32.        if predicate in RELATION_MAP:
33.            relation, tail_type = RELATION_MAP[predicate]
34.            WRITE_TRIPLE(head, head_type, relation, value, tail_type)
35.            continue
36.
37.        // 处理反向关系
38.        if predicate in REVERSE_RELATION_MAP:
39.            relation, new_tail_type, new_head_type = REVERSE_RELATION_MAP[predicate]
40.            new_head, _ = PARSE_ENTITY(value)
41.            WRITE_TRIPLE(new_head, new_head_type, relation, head, new_tail_type)

42. function WRITE_TRIPLE(head, head_type, relation, tail, tail_type):
43.    key = (head, relation, tail)
44.    if key in seen_triples:
45.        return  // 跳过重复
46.    seen_triples.add(key)
47.
48.    triple = {
49.        "head": head,
50.        "head_type": head_type,
51.        "relation": relation,
52.        "tail": tail,
53.        "tail_type": tail_type,
54.        "source": "CM3KG",
55.        "confidence": 1.0
56.    }
57.    output_triples.append(triple)
```

---

## 五、实践设置

### 5.1 数据集

#### 5.1.1 CM3KG数据集

CM3KG（Chinese Medical 3-tuple Knowledge Graph）是中文医学常识知识图谱，包含：

| 文件 | 记录数 | 说明 |
|-----|-------|------|
| Disease.csv | ~600,000 | 疾病相关三元组 |
| medical.csv | ~8,000 | 疾病详细信息 |

数据统计：
- **转换后三元组**：486,647条
- **属性记录**：148,038条
- **实体类型**：Disease, Symptom, Drug, Exam, Food, Department, Treatment

#### 5.1.2 数据格式

**Disease.csv** 示例：

```
感冒[疾病],症状,发热
感冒[疾病],症状,咳嗽
肺炎[疾病],并发症,呼吸衰竭
```

**medical.csv** 示例：

```csv
name,symptom,check,recommand_drug,desc
感冒,"['发热','咳嗽']","['血常规']","['感冒灵']","感冒是..."
```

**输出JSONL格式**：

```json
{"head": "感冒", "head_type": "Disease", "relation": "HAS_SYMPTOM", "tail": "发热", "tail_type": "Symptom", "source": "CM3KG", "confidence": 1.0}
```

### 5.2 实验环境

#### 5.2.1 硬件环境

| 组件 | 规格 |
|-----|-----|
| CPU | Intel Core i7 |
| 内存 | 16GB |
| 存储 | SSD 256GB |
| GPU | NVIDIA GTX 4060 |

#### 5.2.2 软件环境

| 软件 | 版本 |
|-----|-----|
| 操作系统 | Windows 10/11, Ubuntu 20.04+ |
| Python | 3.10+ |
| Neo4j | 5.x |
| PyTorch | 2.0+ |
| Transformers | 4.30+ |

#### 5.2.3 主要依赖

```
neo4j==5.x           # Neo4j Python驱动
transformers==4.30+  # BERT模型
torch==2.0+          # 深度学习框架
pyyaml==6.0+         # 配置文件解析
fastapi==0.100+      # REST API框架
uvicorn==0.23+       # ASGI服务器
```

### 5.3 评估指标

#### 5.3.1 核心指标定义

| 指标 | 公式 | 说明 |
|-----|------|------|
| 可执行率 | $\frac{\text{成功执行查询数}}{\text{总查询数}}$ | 查询能否正常执行 |
| Accuracy@1 | $\frac{\text{首结果正确数}}{\text{总查询数}}$ | 第一个结果的准确率 |
| Precision | $\frac{TP}{TP + FP}$ | 返回结果的精确率 |
| Recall | $\frac{TP}{TP + FN}$ | 正确答案的召回率 |
| F1 Score | $\frac{2 \cdot P \cdot R}{P + R}$ | 精确率和召回率的调和平均 |
| Coverage | $\frac{\text{有结果返回数}}{\text{总查询数}}$ | 能返回结果的比例 |
| Latency | $P50, P95$ | 响应时间分布 |

#### 5.3.2 评估数据集

评估数据包含两类意图：
- **disease_to_symptom**：200个样本，询问疾病的症状
- **symptom_to_disease**：200个样本，询问症状对应的疾病

### 5.4 实验结果

#### 5.4.1 总体性能

| 指标 | 值 |
|-----|-----|
| 总样本数 | 400 |
| 可执行率 | 100.00% |
| Accuracy@1 | **97.00%** |
| 平均Precision | 0.9715 |
| 平均Recall | 0.8918 |
| 平均F1 | **0.9082** |
| Coverage | 100.00% |
| Latency P50 | 10ms |
| Latency P95 | 15ms |

#### 5.4.2 分意图性能

| 意图 | 样本数 | 可执行率 | Accuracy@1 | 平均F1 | Coverage |
|-----|--------|---------|-----------|-------|---------|
| disease_to_symptom | 200 | 100.00% | 97.50% | 0.9730 | 100.00% |
| symptom_to_disease | 200 | 100.00% | 96.50% | 0.8434 | 100.00% |

#### 5.4.3 结果分析

1. **整体性能优异**：
   - Accuracy@1达到97%，F1分数达到0.9082
   - 两类意图均表现出色，验证了系统的有效性

2. **disease_to_symptom**：
   - 准确率97.50%，F1分数0.9730
   - 疾病到症状的关系覆盖完整，查询效果稳定

3. **symptom_to_disease**：
   - 准确率96.50%，F1分数0.8434
   - 通过优化意图识别正则表达式匹配顺序，显著提升了性能
   - 失败样本数从43个降至0个

4. **响应时间优秀**：
   - P50仅10ms，P95为15ms
   - 得益于Neo4j索引优化和批量导入策略

#### 5.4.4 优化历程

系统经历了多轮优化迭代：

| 版本 | Accuracy@1 | 主要问题 | 优化措施 |
|-----|-----------|---------|---------|
| v1.0 | 48.50% | symptom_to_disease 0% | 缺少反向关系处理 |
| v1.1 | 77.00% | 43个样本无结果 | 添加反向关系映射 |
| v1.2 | **97.00%** | - | 优化意图识别正则顺序 |

关键修复：**意图识别正则匹配顺序问题**

原始代码中，通用模式 `(.+?)的症状` 优先于具体模式 `哪些疾病会出现(.+?)的症状`，导致问题被错误分类。修复后将具体模式放在前面，显著提升了 symptom_to_disease 意图的识别准确率。

#### 5.4.5 延迟分析

最慢 Top-5 样本：

| 问题 | 意图 | 延迟(ms) |
|-----|------|---------|
| 胃,十二指肠溃疡出血有什么表现？ | disease_to_symptom | 23 |
| 输入袢综合征有什么表现？ | disease_to_symptom | 23 |
| 假膜性肠炎有什么表现？ | disease_to_symptom | 22 |
| 甲亢有哪些症状？ | disease_to_symptom | 19 |
| 汽油中毒有什么表现？ | disease_to_symptom | 18 |

所有查询延迟均在25ms以内，满足实时问答需求

### 5.5 系统部署

#### 5.5.1 启动流程

```bash
# 1. 数据转换
python -m ingest.convert_cm3kg --cm3kg_dir data/CM3KG --out data/triples_raw/cm3kg_triples.jsonl

# 2. 知识融合
python run_pipeline.py

# 3. 启动API服务
python -m api.main

# 4. 运行评估
python -m eval.runner
```

#### 5.5.2 API接口

```
POST /ask
{
    "question": "肺炎的症状是什么？",
    "top_k": 10
}

Response:
{
    "intent": "disease_to_symptom",
    "entity": "肺炎",
    "results": ["咳嗽", "发热", "呼吸困难", ...],
    "latency_ms": 8
}
```

---

## 附录

### A. 项目结构

```
kgqa/
├── api/                    # REST API服务
│   └── main.py
├── data/
│   ├── CM3KG/             # 原始数据
│   │   ├── Disease.csv
│   │   └── medical.csv
│   └── triples_raw/       # 转换后数据
├── eval/                   # 评估模块
│   └── runner.py
├── fusion/                 # 知识融合
│   ├── pipeline.py
│   ├── linking.py
│   ├── conflict.py
│   └── scoring.py
├── ingest/                 # 数据导入
│   ├── convert_cm3kg.py
│   └── neo4j_importer.py
├── nlp/                    # NLP模块
│   ├── ner.py
│   └── relation.py
├── reports/                # 评估报告
├── config.yaml            # 配置文件
└── run_pipeline.py        # 主流程
```

### B. 配置说明

```yaml
neo4j:
  uri: "bolt://localhost:7687"
  user: "neo4j"
  password: "password"

fusion:
  enable_fuzzy: false      # 是否启用模糊匹配
  fuzzy_threshold: 90      # 模糊匹配阈值
  source_weights:
    CM3KG: 1.0
    default: 1.0
  scoring:
    frequency_weight: 0.3
    source_weight: 0.3
    confidence_weight: 0.4

nlp:
  ner:
    model: "models/ner_cmeee"
    device: "cuda:0"
```
